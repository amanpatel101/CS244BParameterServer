{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from filelock import FileLock\n",
    "import numpy as np\n",
    "import ray\n",
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "from consistent_hashing import ConsistentHash\n",
    "import math \n",
    "from time import time\n",
    "def get_data_loader():\n",
    "    \n",
    "    \"\"\"Safely downloads data. Returns training/validation set dataloader.\"\"\"\n",
    "    mnist_transforms = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "    )\n",
    "\n",
    "    # We add FileLock here because multiple workers will want to\n",
    "    # download data, and this may cause overwrites since\n",
    "    # DataLoader is not threadsafe.\n",
    "    \n",
    "    class MNISTEvenOddDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, ready_data):\n",
    "            self.img_data = ready_data.data\n",
    "            self.labels = ready_data.targets % 2\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.labels)\n",
    "    \n",
    "        def __getitem__(self, ind):\n",
    "            return torch.true_divide(self.img_data[ind].view(-1, 28 * 28).squeeze(), 255), torch.tensor([self.labels[ind]])\n",
    "\n",
    "\n",
    "    \n",
    "    with FileLock(os.path.expanduser(\"~/data.lock\")):\n",
    "        \n",
    "        train_dataset = datasets.MNIST(\n",
    "                \"~/data\", train=True, download=True, transform=mnist_transforms\n",
    "            )\n",
    "        \n",
    "        test_dataset = datasets.MNIST(\"~/data\", train=False, transform=mnist_transforms)\n",
    "        \n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            MNISTEvenOddDataset(train_dataset),\n",
    "            batch_size=128,\n",
    "            shuffle=True,\n",
    "        )\n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "             MNISTEvenOddDataset(test_dataset),\n",
    "            batch_size=128,\n",
    "            shuffle=False,\n",
    "        )\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    \"\"\"Evaluates the accuracy of the model on a validation dataset.\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            # This is only set to finish evaluation faster.\n",
    "            if batch_idx * len(data) > 1024:\n",
    "                break\n",
    "            outputs = nn.Sigmoid()(model(data))\n",
    "            #_, predicted = torch.max(outputs.data, 1)\n",
    "            predicted = outputs > 0.5\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    return 100.0 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearNet(nn.Module):\n",
    "    \"\"\"Small Linear Network for MNIST.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self.fc_weights = nn.ParameterList([nn.Parameter(torch.empty(1)) for weight in range(784)])\n",
    "        init_fc = [nn.init.uniform_(x) for x in self.fc_weights]\n",
    "        \n",
    "        self.fc_bias = nn.Parameter(torch.empty(1))\n",
    "        nn.init.uniform_(self.fc_bias)\n",
    "        \n",
    "    #def __init__(self):\n",
    "    #    super(LinearNet, self).__init__()\n",
    "    #    self.fc = nn.Linear(28*28, 1)\n",
    "    #    nn.init.normal(self.fc.weight)\n",
    "\n",
    "    #def forward(self, x):\n",
    "    #    x = self.fc(x)\n",
    "    #    return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #fc_layer = torch.cat(tuple(self.fc_weights)).unsqueeze(0)\n",
    "        #x = x @ fc_layer.T + self.fc_bias\n",
    "        for i, param in enumerate(self.fc_weights):\n",
    "            if i==0:\n",
    "                p=x[:,i]*param\n",
    "            else:\n",
    "                p += x[:,i]*param\n",
    "        x = p.unsqueeze(1) + self.fc_bias\n",
    "        return x\n",
    "    \n",
    "    def get_weights(self):\n",
    "        return {k: v.cpu() for k, v in self.state_dict().items()}\n",
    "\n",
    "    def set_weights(self, keys, weights): \n",
    "        flatten_weights =  [item for sublist in weights for item in sublist]\n",
    "        self.load_state_dict({keys[i]:flatten_weights[i] for i in range(len(keys))})\n",
    "        \n",
    "    def get_gradients(self, keys):\n",
    "        grads = {}\n",
    "\n",
    "        for name, p in self.named_parameters():\n",
    "            if name in keys:\n",
    "                grad = None if p.grad is None else p.grad.data.cpu().numpy()\n",
    "                grads[name] = grad\n",
    "\n",
    "        return [grads[key] for key in keys]\n",
    "\n",
    "    def set_gradients(self, gradients):\n",
    "        for g, p in zip(gradients, self.parameters()):\n",
    "            if g is not None:\n",
    "                p.grad = torch.from_numpy(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote  \n",
    "class ParameterServer(object):\n",
    "    def __init__(self, keys, values):\n",
    "        self.weights = dict(zip(keys, values))\n",
    "\n",
    "    def apply_gradients(self, keys, lr, *values):\n",
    "        summed_gradients = [\n",
    "            np.stack(gradient_zip).sum(axis=0) for gradient_zip in zip(*values)\n",
    "        ]\n",
    "    \n",
    "        idx = 0\n",
    "        for key, value in zip(keys, summed_gradients):\n",
    "            self.weights[key] -= lr * torch.from_numpy(summed_gradients[idx])\n",
    "            idx+=1\n",
    "\n",
    "        return [self.weights[key] for key in keys]\n",
    "    \n",
    "    def add_weight(self, key, value):\n",
    "        self.weights[key] = value\n",
    "    \n",
    "    def get_len(self):\n",
    "        return len(self.weights)\n",
    "    \n",
    "    def get_weights(self, keys):\n",
    "        return [self.weights[key] for key in keys]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class DataWorker(object):\n",
    "    def __init__(self, keys):\n",
    "        self.model = LinearNet()\n",
    "        self.data_iterator = iter(get_data_loader()[0])\n",
    "        self.keys = keys\n",
    "        self.key_set = set(self.keys)\n",
    "        for key, value in dict(self.model.named_parameters()).items():\n",
    "            if key not in self.key_set:\n",
    "                value.requires_grad=False\n",
    "\n",
    "        \n",
    "    def update_weights(self, keys, *weights):\n",
    "        self.model.set_weights(keys, weights)\n",
    "        \n",
    "#     def update_weights_selected(self, keys, *weights):\n",
    "#         curr_state_dict = dict(self.model.state_dict().items())\n",
    "#         flatten_weights =  [item for sublist in weights for item in sublist]\n",
    "#         for i, key in enumerate(keys):\n",
    "#             curr_state_dict[keys] = flatten_weights[i]\n",
    "#         self.model.load_state_dict(curr_state_dict)\n",
    "        \n",
    "    def update_trainable(self, keys):\n",
    "        self.keys = keys\n",
    "        self.key_set = set(self.keys)\n",
    "        for key, value in dict(self.model.named_parameters()).items():\n",
    "            if key in self.key_set:\n",
    "                value.requires_grad = True\n",
    "            else:\n",
    "                value.requires_grad = False\n",
    "       \n",
    "\n",
    "    def compute_gradients(self):\n",
    "        #self.model.set_weights(keys, weights)\n",
    "        try:\n",
    "            data, target = next(self.data_iterator)\n",
    "        except StopIteration:  # When the epoch ends, start a new epoch.\n",
    "            self.data_iterator = iter(get_data_loader()[0])\n",
    "            data, target = next(self.data_iterator)\n",
    "        \n",
    "        self.model.zero_grad()\n",
    "        output = self.model(data)\n",
    "        loss = nn.BCEWithLogitsLoss()(output, target.float())\n",
    "        loss.backward()\n",
    "        \n",
    "        return self.model.get_gradients(self.keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-31 21:17:03,600\tINFO worker.py:963 -- Calling ray.init() again after it has already been called.\n"
     ]
    }
   ],
   "source": [
    "iterations = 100\n",
    "num_workers = 1 # number of workers per server\n",
    "num_servers = 5 # number of servers\n",
    "hashes_per_server = 100\n",
    "\n",
    "def Scheduler(num_servers, hashes_per_server=50):\n",
    "    \n",
    "    model = LinearNet()\n",
    "    key_values = model.get_weights()\n",
    "    keys = np.array(list(key_values.keys()))\n",
    "    #print(keys)\n",
    "    #print(key_values) z\n",
    "    values = [key_values[key] for key in keys]\n",
    "    #values = [key_values[key] for key in keys]\n",
    "    \n",
    "    key_indices = {key: x for x, key in enumerate(keys)}\n",
    "   \n",
    "    # distributing weights across servers - do this using consistency hashing\n",
    "    server_ids = [\"server\" + str(ind) for ind in range(num_servers)]\n",
    "    hasher = ConsistentHash(keys, server_ids, hashes_per_server)\n",
    "    servers = [ParameterServer.remote(keys[[key_indices[key] for key in hasher.get_keys_per_node()[serv]]], \n",
    "                                      [values[key_indices[key]] for key in hasher.get_keys_per_node()[serv]]) for serv in server_ids]\n",
    "    # servers = [ParameterServer.remote(keys[0:1], values[0:1]), ParameterServer.remote(keys[1:2], values[1:2])]\n",
    "    \n",
    "    return hasher, servers, keys, model, hasher.get_keys_per_node(), server_ids.copy()\n",
    "\n",
    "hasher, servers, keys, model, weight_assignments, server_ids =  Scheduler(num_servers, hashes_per_server)\n",
    "ray.init(ignore_reinit_error=True)\n",
    "\n",
    "# creating equal workers per server\n",
    "\n",
    "workers = [[DataWorker.remote(weight_assignments[\"server\" + str(j)]) for i in range(num_workers)] for j in range(num_servers)]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Actor(ParameterServer, aeee65985d4641ba756498cd01000000),\n",
       " Actor(ParameterServer, f56644e366d09b448f3163ed01000000),\n",
       " Actor(ParameterServer, 09925249890f610c05ef082901000000),\n",
       " Actor(ParameterServer, 787e81a6b1b7ca44d557a2e701000000),\n",
       " Actor(ParameterServer, b2512bfecd02d5bacf6d264f01000000)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weight_assignments[\"server0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['server0', 'server1']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = get_data_loader()[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running synchronous parameter server training.\n",
      "Iter 0: \taccuracy is 51.9\n",
      "Iter 1: \taccuracy is 51.9\n",
      "Iter 2: \taccuracy is 51.9\n",
      "Iter 3: \taccuracy is 51.9\n",
      "Iter 4: \taccuracy is 51.9\n",
      "Iter 5: \taccuracy is 51.9\n",
      "Iter 6: \taccuracy is 51.9\n",
      "Iter 7: \taccuracy is 51.9\n",
      "Iter 8: \taccuracy is 51.9\n",
      "Iter 9: \taccuracy is 51.9\n",
      "Iter 10: \taccuracy is 51.9\n",
      "Iter 11: \taccuracy is 51.9\n",
      "Iter 12: \taccuracy is 51.9\n",
      "Iter 13: \taccuracy is 51.9\n",
      "Iter 14: \taccuracy is 51.9\n",
      "Iter 15: \taccuracy is 51.9\n",
      "Iter 16: \taccuracy is 51.9\n",
      "Iter 17: \taccuracy is 51.9\n",
      "Iter 18: \taccuracy is 51.9\n",
      "Iter 19: \taccuracy is 51.9\n",
      "Iter 20: \taccuracy is 52.3\n",
      "Iter 21: \taccuracy is 52.3\n",
      "Iter 22: \taccuracy is 52.7\n",
      "Iter 23: \taccuracy is 49.7\n",
      "Iter 24: \taccuracy is 45.7\n",
      "Iter 25: \taccuracy is 43.5\n",
      "Iter 26: \taccuracy is 44.4\n",
      "Iter 27: \taccuracy is 44.8\n",
      "Iter 28: \taccuracy is 45.8\n",
      "Iter 29: \taccuracy is 46.6\n",
      "Iter 30: \taccuracy is 47.1\n",
      "Iter 31: \taccuracy is 48.1\n",
      "Iter 32: \taccuracy is 49.7\n",
      "Iter 33: \taccuracy is 51.8\n",
      "Iter 34: \taccuracy is 53.5\n",
      "Iter 35: \taccuracy is 54.2\n",
      "Iter 36: \taccuracy is 55.6\n",
      "Iter 37: \taccuracy is 56.9\n",
      "Iter 38: \taccuracy is 58.0\n",
      "Iter 39: \taccuracy is 58.9\n",
      "Iter 40: \taccuracy is 59.5\n",
      "Iter 41: \taccuracy is 60.2\n",
      "Iter 42: \taccuracy is 61.1\n",
      "Iter 43: \taccuracy is 61.5\n",
      "Iter 44: \taccuracy is 61.8\n",
      "Iter 45: \taccuracy is 62.7\n",
      "Iter 46: \taccuracy is 63.9\n",
      "Iter 47: \taccuracy is 65.3\n",
      "Iter 48: \taccuracy is 66.4\n",
      "Iter 49: \taccuracy is 66.8\n",
      "Iter 50: \taccuracy is 66.8\n",
      "Iter 51: \taccuracy is 67.1\n",
      "Iter 52: \taccuracy is 67.6\n",
      "Iter 53: \taccuracy is 68.0\n",
      "Iter 54: \taccuracy is 68.7\n",
      "Iter 55: \taccuracy is 69.1\n",
      "Iter 56: \taccuracy is 69.2\n",
      "Iter 57: \taccuracy is 69.5\n",
      "Iter 58: \taccuracy is 69.7\n",
      "Iter 59: \taccuracy is 70.1\n",
      "Iter 60: \taccuracy is 70.4\n",
      "Iter 61: \taccuracy is 71.3\n",
      "Iter 62: \taccuracy is 71.4\n",
      "Iter 63: \taccuracy is 71.9\n",
      "Iter 64: \taccuracy is 72.2\n",
      "Iter 65: \taccuracy is 72.6\n",
      "Iter 66: \taccuracy is 72.3\n",
      "Iter 67: \taccuracy is 72.9\n",
      "Iter 68: \taccuracy is 73.1\n",
      "Iter 69: \taccuracy is 73.9\n",
      "Iter 70: \taccuracy is 73.8\n",
      "Iter 71: \taccuracy is 73.8\n",
      "Iter 72: \taccuracy is 73.4\n",
      "Iter 73: \taccuracy is 73.5\n",
      "Iter 74: \taccuracy is 73.5\n",
      "Iter 75: \taccuracy is 73.8\n",
      "Iter 76: \taccuracy is 74.2\n",
      "Iter 77: \taccuracy is 74.2\n",
      "Iter 78: \taccuracy is 74.6\n",
      "Iter 79: \taccuracy is 74.7\n",
      "Iter 80: \taccuracy is 74.7\n",
      "Iter 81: \taccuracy is 74.8\n",
      "Iter 82: \taccuracy is 74.9\n",
      "Iter 83: \taccuracy is 75.0\n",
      "Iter 84: \taccuracy is 75.0\n",
      "Iter 85: \taccuracy is 75.2\n",
      "Iter 86: \taccuracy is 75.4\n",
      "Iter 87: \taccuracy is 75.7\n",
      "Iter 88: \taccuracy is 75.4\n",
      "Iter 89: \taccuracy is 76.2\n",
      "Iter 90: \taccuracy is 76.0\n",
      "Iter 91: \taccuracy is 76.1\n",
      "Iter 92: \taccuracy is 76.1\n",
      "Iter 93: \taccuracy is 76.1\n",
      "Iter 94: \taccuracy is 76.2\n",
      "Iter 95: \taccuracy is 76.3\n",
      "Iter 96: \taccuracy is 76.6\n",
      "Iter 97: \taccuracy is 76.7\n",
      "Iter 98: \taccuracy is 76.6\n",
      "Iter 99: \taccuracy is 76.7\n"
     ]
    }
   ],
   "source": [
    "print(\"Running synchronous parameter server training.\")\n",
    "lr=0.1\n",
    "failure_iter=200\n",
    "failure_server=\"server1\"\n",
    "\n",
    "# we need to get a new keys order because we are not assuming a ordering in keys\n",
    "current_weights = []\n",
    "keys_order = []\n",
    "acc_vals = []\n",
    "\n",
    "for j in range(num_servers):\n",
    "    keys_order.extend(weight_assignments[server_ids[j]])\n",
    "    current_weights.append(ray.get(servers[j].get_weights.remote(weight_assignments[server_ids[j]]))) \n",
    "curr_weights_ckpt = current_weights.copy()\n",
    "\n",
    "time_per_iteration = []\n",
    "for i in range(iterations):\n",
    " \n",
    "    #start = time()\n",
    "    \n",
    "    if i == failure_iter:\n",
    "        server_ids_old = server_ids.copy()\n",
    "        weight_assignments_old = weight_assignments.copy()\n",
    "        #Define parameters that will need to be moved\n",
    "        failure_params = weight_assignments[failure_server]\n",
    "        #Delete server from hash ring and reassign params\n",
    "        hasher.delete_node_and_reassign_to_others(failure_server)\n",
    "        weight_assignments = hasher.get_keys_per_node()\n",
    "        #Update servers and workers\n",
    "        num_servers -= 1\n",
    "        server_ind = server_ids.index(failure_server)\n",
    "        server_ids = server_ids[0 : server_ind] + server_ids[server_ind + 1 : ]\n",
    "        servers = servers[0 : server_ind] + servers[server_ind + 1 : ]\n",
    "        workers = workers[0 : server_ind] + workers[server_ind + 1 : ]\n",
    "        #Add each relevant parameter to its new server\n",
    "        server_dict = {server_ids[x]:servers[x] for x in range(len(server_ids))}\n",
    "        for ind, param in enumerate(failure_params):\n",
    "            server_dict[hasher.get_key_to_node_map()[param]].add_weight.remote(param, curr_weights_ckpt[server_ind][ind])\n",
    "        for server in server_ids:\n",
    "            sid = server_ids_old.index(server)\n",
    "            for ind, param in enumerate(weight_assignments_old[server]):\n",
    "                server_dict[server].add_weight.remote(param, curr_weights_ckpt[sid][ind])\n",
    "        #Update these parameters for each worker to make them trainable\n",
    "        [workers[j][idx].update_trainable.remote(weight_assignments[server_ids[j]]) for  idx  in range(num_workers) for j in range(num_servers)]\n",
    "        #print(\"at failure\", np.mean(current_weights))\n",
    "        current_weights = curr_weights_ckpt.copy()\n",
    "        #print(\"at failure\", np.mean(current_weights))\n",
    "        [workers[j][idx].update_weights.remote(keys_order, *current_weights) for  idx  in range(num_workers) for j in range(num_servers)]\n",
    "\n",
    "    #time_per_iteration.append(end-start)\n",
    "\n",
    "    if i % 1 == 0:\n",
    "        #print(len(keys_order))\n",
    "        #print(len(current_weights[0]))\n",
    "        # Evaluate the current model.\n",
    "        #current_weights = [servers[j].get_weights.remote(weight_assignments[\"server\" + str(j)]) for j in range(num_servers)] \n",
    "      \n",
    "        # we are once again using the server to key mapping to set the weight back\n",
    "        \n",
    "        model.set_weights(keys_order, current_weights)\n",
    "        accuracy = evaluate(model, test_loader)\n",
    "        acc_vals.append(accuracy)\n",
    "        print(\"Iter {}: \\taccuracy is {:.1f}\".format(i, accuracy))\n",
    "   \n",
    "\n",
    "  \n",
    "    # sync all weights on workers\n",
    "    if i % 5 == 0:\n",
    "\n",
    "#         print(\"before\",np.mean(curr_weights_ckpt[0]))\n",
    "        curr_weights_ckpt = current_weights.copy()\n",
    "#         print(\"after\",np.mean(curr_weights_ckpt[0]))\n",
    "\n",
    "        # get weights from server\n",
    "        #current_weights = [servers[j].get_weights.remote(weight_assignments[\"server\" + str(j)]) for j in range(num_servers)] \n",
    "\n",
    "        # update weights on all workers\n",
    "        [workers[j][idx].update_weights.remote(keys_order, *current_weights) for  idx  in range(num_workers) for j in range(num_servers)]\n",
    "    \n",
    "        \n",
    "    # use local cache of weights and get gradients from workers\n",
    "    gradients = [[workers[j][idx].compute_gradients.remote() for  idx  in range(num_workers)] for j in range(num_servers)]\n",
    "\n",
    "#     start = time()\n",
    "\n",
    "    if i == failure_iter:\n",
    "        keys_order = []\n",
    "        for j in range(num_servers):\n",
    "            keys_order.extend(weight_assignments[server_ids[j]])\n",
    "\n",
    "\n",
    "    # Updates gradients to specfic parameter servers\n",
    "    current_weights_t = [servers[j].apply_gradients.remote(weight_assignments[server_ids[j]], lr, *gradients[j]) for j in range(num_servers)]\n",
    "    current_weights = ray.get(current_weights_t)\n",
    "\n",
    "       \n",
    "    end = time()\n",
    "\n",
    "      \n",
    "\n",
    "    #rint(\"\\n\")\n",
    "\n",
    "#print(\"Final accuracy is {:.1f}.\".format(accuracy))\n",
    "# Clean up Ray resources and processes before the next example.\n",
    "ray.shutdown()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/anusri/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/users/anusri/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(time_per_iteration[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/anusri/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:234: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "/users/anusri/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:195: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "/users/anusri/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(time_per_iteration[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_per_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['server0', 'server1']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'server4' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a58e50e12838>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mserver_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"server4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: 'server4' is not in list"
     ]
    }
   ],
   "source": [
    "server_ids.index(\"server4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasher.get_key_to_node_map()['fc_bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testmodel=LinearNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(testmodel.state_dict().items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(current_weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "servers[0].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([184, 198, 191, 212])\n",
    "len(acc_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6c08b08c10>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.plot(acc_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[69.09722222222223,\n",
       " 69.18402777777777,\n",
       " 69.53125,\n",
       " 69.70486111111111,\n",
       " 70.13888888888889,\n",
       " 70.39930555555556,\n",
       " 71.26736111111111,\n",
       " 71.44097222222223,\n",
       " 71.875,\n",
       " 72.22222222222223]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_vals[55:65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_failure_test = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ParamServer",
   "language": "python",
   "name": "paramserver"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
